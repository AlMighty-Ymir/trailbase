---
title: >
  First App: UI & Custom Endpoints
---

import { Code } from "@astrojs/starlight/components";

In this tutorial, we'll set up a database with coffee data, implement a custom
handler for vector search in TypeScript, and a simple web UI all in ~100 lines
of code.


<div class="flex justify-center">
  <div class="w-[80%] shadow-lg	 ">
    ![screenshot](../../../../../examples/coffeesearch/assets/screenshot.png)
  </div>
</div>

{/*
<div class="flex justify-center">
  <Image
    class="w-[80%] "
    src={screenshot}
    alt="Screenshot of Coffee Vector Search App"
  />
</div>
*/}

## Importing the Data

The dataset live under `/examples/coffeesearch/arabica_data_cleaned.csv`. We'll
use the `sqlite3` CLI and the following SQL script to import the initial data:

```sql
-- First create the strictly typed "coffee" table.
CREATE TABLE IF NOT EXISTS coffee (
  Species TEXT,
  Owner TEXT,

  Aroma REAL,
  Flavor REAL,
  Acidity REAL,
  Sweetness REAL,

  embedding BLOB
) STRICT;

-- Then import the data into a "temporary" table.
.mode csv
.import arabica_data_cleaned.csv temporary

-- Then import the temporary data into the "coffee" table.
INSERT INTO coffee (Species, Owner, Aroma, Flavor, Acidity, Sweetness)
SELECT
  Species,
  Owner,

  CAST(Aroma AS REAL) AS Aroma,
  CAST(Flavor AS REAL) AS Flavor,
  CAST(Acidity AS REAL) AS Acidity,
  CAST(Sweetness AS REAL) AS Sweetness
FROM temporary;

-- And clean up.
DROP TABLE temporary;
```

Note that we didn't initialize the vector `embedding`. This is because the
`sqlite3` CLI doesn't have the necessary extension functions built-in.
We'll update the entries to add the embedding later as part of a TrailBase
migration.

With this script as `import.sql` and assuming `/example/coffeesearch` is your
current working directory, you can run:

```bash
$ cat import.sql | sqlite3 traildepot/data/main.db -
```

Now with the initial import, let's start TrailBase for the first time. This
will apply the migrations under `/examples/coffeesearch/traildepot/migrations`,
basically:

```sql
UPDATE coffee SET embedding = VECTOR(FORMAT("[%f, %f, %f, %f]", Aroma, Flavor, Acidity, Sweetness));
```

late-initializing `coffee.embedding`s for all records. So we run:

```bash
$ trail run
```

If the server comes up successfully, you've done everything right.

# A JS/TS Vector Search Handler

Let's have a quick look at the custom TS/JS HTTP endpoint defined in
`/examples/coffeesearch/traildepot/scripts/main.ts` that our UI will use to
find the coffee that most closely matches our desired notes:

import handlerCode from "../../../../../examples/coffeesearch/traildepot/scripts/main.ts?raw";

<Code
  code={handlerCode}
  lang="ts"
  title={"examples/coffeesearch/traildepot/scripts/main.ts"}
  mark={[]}
/>

The above script installs an `get('/search')` HTTP endpoint that reads notes
from the query parameters and looks up coffees in the database ordered by
vector distance, i.e. how well they match.

This is a public API. While `trail` is up, we can simply test it by running:

```bash
$ curl "http://localhost:4000/search?aroma=8&flavor=8&acidity=8&sweetness=8"
[
  ["juan luis alvarado romero",7.92,7.58,7.58,8,0.0003054438275285065],
  ["eileen koyanagi",7.5,7.33,7.58,8,0.000525727984495461],
  ...
]
```

We're done with the server side. This is already enough to build a simple UI.
With a few simple commands we've ingested CSV data and built a custom HTTP
endpoint using vector search.
If you're not interested in a UI, the same approach setup could also be used to
identify relevant documents for AI applications.

## A simple Web UI

After setting up our database, vector search and APIs, we should probably use
them for good measure. We could build a mobile app, have an LLM answer coffee
prompts, or to keep it simple: build a small web UI.
Moreover, a web UI also lets us touch more generally on bundling and deploying
web applications with TrailBase.

The specifics of the UI are not the focus of this tutorial that's why we
chose React as the most well-known option and kept the implementation to less
than 80 lines of code. In case you want to build your own, we recommend
[vite](https://vite.dev/guide/) to quickly set up an SPA with your favorite JS
framework, e.g.: `pnpm create vite@latest my-project -- --template react`.

Our reference implementation, renders 4 numeric input fields to search for
coffee with a given aroma, flavor, acidity and sweetness score:

import uiCode from "../../../../../examples/coffeesearch/src/App.tsx?raw";

<Code
  code={uiCode}
  lang="ts"
  title={"examples/coffeesearch/src/App.tsx"}
  mark={[]}
/>

We can run the UI in a vite dev-server by running:

```bash
pnpm install && pnpm dev
```

## Deployment: Putting Everything Together

Whether you've followed along or skipped to here, we can now put everything
together.
Let's start by compiling our `JSX/TSX` web UI down to pure HTML, JS, and CSS
artifacts the browser can understand by running:

```bash
pnpm install && pnpm build
```

These artifacts, found in `./dist`, can then be served alongside our data and
custom API simply by running:

```bash
trail run --public-dir dist
```

You can now check out your fuly self-contained app under
[http://localhost:4000/](http://localhost:4000/) or browse the coffee data in
the [admin dashboard](http://localhost:4000/_/admin).

All we need to serve our application in production is[^1]:

- the static `trail` binary,
- the `traildepot` folder containing the data and endpoints,
- the `dist` folder containing our web app.

At the end of the day it's just a bunch of hermetic files without transitively
depending on a pyramid of shared libraries or other services including
databases.
This makes it very easy to just copy the files over to your server or bundle
everything in a single container.
`examples/coffeesearch/Dockerfile` is an example of how you can both build and
bundle using Docker.

<div class="h-[50px]" />

----

[^1]:
    To serve HTTPS you'll either need a reverse proxy in front to terminate TLS
    or if you don't require end-to-end encryption (e.g. you're not using auth
    or handling sensitive data) you can fall back to TLS termination via a CDN
    like cloudflare.
